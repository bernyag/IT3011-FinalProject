{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37564bitdac362f9e64743bba67d79098195eeb6",
   "display_name": "Python 3.7.5 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Creating input data...\nTrain on 27780 samples, validate on 6945 samples\nEpoch 1/15\n27780/27780 [==============================] - 29s 1ms/step - loss: 2.2466 - accuracy: 0.1757 - val_loss: 2.2368 - val_accuracy: 0.1587\nEpoch 2/15\n27780/27780 [==============================] - 29s 1ms/step - loss: 2.2355 - accuracy: 0.1788 - val_loss: 2.2350 - val_accuracy: 0.1785\nEpoch 3/15\n27780/27780 [==============================] - 29s 1ms/step - loss: 1.7355 - accuracy: 0.3943 - val_loss: 1.0213 - val_accuracy: 0.6688\nEpoch 4/15\n27780/27780 [==============================] - 29s 1ms/step - loss: 0.7079 - accuracy: 0.7794 - val_loss: 0.3906 - val_accuracy: 0.8878\nEpoch 5/15\n27780/27780 [==============================] - 29s 1ms/step - loss: 0.3687 - accuracy: 0.8942 - val_loss: 0.2440 - val_accuracy: 0.9320\nEpoch 6/15\n27780/27780 [==============================] - 30s 1ms/step - loss: 0.2712 - accuracy: 0.9237 - val_loss: 0.1831 - val_accuracy: 0.9473\nEpoch 7/15\n27780/27780 [==============================] - 30s 1ms/step - loss: 0.2139 - accuracy: 0.9396 - val_loss: 0.1500 - val_accuracy: 0.9587\nEpoch 8/15\n27780/27780 [==============================] - 28s 1ms/step - loss: 0.1813 - accuracy: 0.9481 - val_loss: 0.1301 - val_accuracy: 0.9639\nEpoch 9/15\n27780/27780 [==============================] - 29s 1ms/step - loss: 0.1570 - accuracy: 0.9552 - val_loss: 0.1216 - val_accuracy: 0.9670\nEpoch 10/15\n27780/27780 [==============================] - 29s 1ms/step - loss: 0.1439 - accuracy: 0.9586 - val_loss: 0.1078 - val_accuracy: 0.9699\nEpoch 11/15\n27780/27780 [==============================] - 29s 1ms/step - loss: 0.1311 - accuracy: 0.9623 - val_loss: 0.1062 - val_accuracy: 0.9683\nEpoch 12/15\n27780/27780 [==============================] - 30s 1ms/step - loss: 0.1219 - accuracy: 0.9647 - val_loss: 0.1415 - val_accuracy: 0.9569\nEpoch 13/15\n27780/27780 [==============================] - 30s 1ms/step - loss: 0.1110 - accuracy: 0.9667 - val_loss: 0.1008 - val_accuracy: 0.9726\nEpoch 14/15\n27780/27780 [==============================] - 30s 1ms/step - loss: 0.1060 - accuracy: 0.9698 - val_loss: 0.0816 - val_accuracy: 0.9783\nEpoch 15/15\n27780/27780 [==============================] - 31s 1ms/step - loss: 0.1009 - accuracy: 0.9705 - val_loss: 0.0846 - val_accuracy: 0.9765\nCNN Error: 2.35%\n"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import csv\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "values=['div','times','+','-','0','1','2','3','4','5','6','7','8','9']\n",
    "train_folder = './images_no_copies/'\n",
    "\n",
    "train_data = []\n",
    "labels = []\n",
    "\n",
    "print(\"Creating input data...\")\n",
    "for foldername in os.listdir(train_folder):\n",
    "    for filename in os.listdir(train_folder + foldername):\n",
    "        img = cv2.imread(train_folder + foldername + \"/\" + filename, cv2.IMREAD_GRAYSCALE)\n",
    "        currLabel=values.index(foldername)\n",
    "        resized_img = cv2.resize(img, (45,45))\n",
    "        img_data = resized_img.flatten() / 255 # flatten to 784 and normalize values\n",
    "        train_data.append(img_data)\n",
    "        labels.append(currLabel)\n",
    "\n",
    "train_data = np.asarray(train_data)\n",
    "labels = np.asarray(labels)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_data, labels, test_size = 0.2, random_state = 101)\n",
    "x_train = x_train.reshape(x_train.shape[0], 45, 45,1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 45, 45,1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "initialsplit=x_train\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(45, 45, 1), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=15, batch_size=40,shuffle=True)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder='./test_dir/'\n",
    "\n",
    "for filename in os.listdir(test_folder):\n",
    "    img = cv2.imread(test_folder+\"/\" + filename, cv2.IMREAD_GRAYSCALE)\n",
    "    resized_img = cv2.resize(img, (45,45))\n",
    "    img_data = resized_img.flatten() / 255\n",
    "    img_data = img_data.reshape(1, 45, 45, 1)\n",
    "    img_data = img_data.astype('float32')\n",
    "    result=model.predict(img_data)\n",
    "    result=values[np.argmax(result)]\n",
    "    print(\"Should be \"+filename)\n",
    "    print(\"Actual \"+result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(6945, 45, 45, 1)\n(6945, 14)\nConfusion Matrix\n[[  37    0    2    0    0    1    0    0    0    0    0    0    0    0]\n [   0  134    0    0    0    0    0    0    0    0    0    0    0    0]\n [   0    0 1085    2    2    8    0    0    1    1    1    2    0    0]\n [   0    0    1 1230    0    3    1    0    0    0    0    0    0    0]\n [   0    0    1    0  340    2    0    0    0    2    2    1    0    0]\n [   0    0    2    0    1 1228    4    1    2    1    0    1    0    0]\n [   0    1    0    0    7   12 1193    1    1    1    0    4    7    2]\n [   0    0    0    0    2    1    4  487    3    3    0    1    1    1]\n [   0    0    2    0    0    1    0    1  307    0    4    0    1    5]\n [   0    0    0    0    0    1    1    0    1  183    4    0    3    0]\n [   0    0    0    0    3    2    1    0    5    1  168    0    2    0]\n [   0    0    1    0    2    0    3    1    1    1    0  123    2    0]\n [   0    2    0    0    1    2    1    0    1    1    0    0  142    0]\n [   0    0    1    0    0    3    1    1    2    1    0    0    0  125]]\n"
    }
   ],
   "source": [
    "y_pred=[]\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "for each in x_test:\n",
    "    each=each.reshape(1,45,45,1)\n",
    "    Y_pred = model.predict(each)\n",
    "    y_pred.append(np.argmax(Y_pred, axis=1))\n",
    "\n",
    "rounded_labels=np.argmax(y_test,axis=1)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "confusionMat = confusion_matrix(rounded_labels,y_pred)\n",
    "print(confusionMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('model.h5')\n",
    "#print(\"Model saved as model.h5\")\n",
    "filename = 'model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  }
 ]
}